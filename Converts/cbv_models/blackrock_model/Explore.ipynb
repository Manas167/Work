{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import BBG_data_process_funcs as data_process\n",
    "import risk_free_curve as rfcurve\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 16]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 19\n",
    "[int(pow(2, b)) for (b, d) in enumerate(reversed(bin(n-1)[2:])) if d == '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat C:/Users/manas/Notebooks/Converts/cbv_models/blackrock_model/AndersonBuffumPricer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file contains functions for risk free curve calibration\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import splev, splrep, splint\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Construct Mark-to-Market Risk Free Discount Curve\n",
    "# from discrete term structure data\n",
    "# -----------------------------------------------------\n",
    "\n",
    "class Libor_Swap_Curve():\n",
    "\n",
    "    def __init__(self, tenors, zero_rates):\n",
    "        n_knots_out = 2\n",
    "        self.knots = np.hstack(\n",
    "            (np.linspace(0, tenors[0], n_knots_out), tenors[1:-1], np.linspace(tenors[-1], 50, n_knots_out)))\n",
    "        self.zero_rates_knots = np.hstack(\n",
    "            (np.ones(n_knots_out) * zero_rates[0], zero_rates[1:-1], np.ones(n_knots_out) * zero_rates[-1]))\n",
    "        self.tenors = tenors\n",
    "        self.zero_rates = zero_rates\n",
    "        self.tck = splrep(self.knots, self.zero_rates_knots)  # B-spline cubic (d=3)\n",
    "        print(self.knots)\n",
    "        print(len(tenors))\n",
    "        print(len(self.knots))\n",
    "        print(len(splrep(self.knots, self.zero_rates_knots, k = 1)[0]))\n",
    "\n",
    "    def continuous_zero_curve(self):\n",
    "        return splev(self.tenors, self.tck)\n",
    "\n",
    "    def continuous_zero_rate(self, t):\n",
    "        return splev(t, self.tck)\n",
    "\n",
    "    def continuous_forward_rate(self, t):\n",
    "        self.derv = splev(t, self.tck, der=1)\n",
    "        return splev(t, self.tck) + self.derv * t\n",
    "\n",
    "    def discount_factor(self, start_t, end_t):\n",
    "        return np.exp(-splint(start_t, end_t, self.tck))\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# class to encapsulate ris.k free rate term structure\n",
    "# -----------------------------------------------------\n",
    "\n",
    "class risk_free_curve():\n",
    "\n",
    "    def __init__(self, tenors, zero_rates):\n",
    "        self.LSC = Libor_Swap_Curve(tenors, zero_rates)\n",
    "\n",
    "    def r(self, t):\n",
    "        return self.LSC.continuous_forward_rate(t)\n",
    "\n",
    "    def Z(self, t):\n",
    "        dt = 0.01\n",
    "        if (t<dt):\n",
    "            return np.exp(-t*self.r(t))\n",
    "        else:\n",
    "            rs = [self.r(s) for s in np.arange(dt,t+1e-4,dt)]\n",
    "            return np.exp(-dt*np.sum(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdate = dt.datetime.strptime('2018/09/21', \"%Y/%m/%d\")\n",
    "pdate_string = pdate.strftime('%d%b%Y')\n",
    "inputfile = 'AndersonBuffum_PricingInput_' + pdate_string + 'Final.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.    0.25  0.5   1.    2.    3.    4.    5.    6.    7.    8.    9.\n",
      " 10.   15.   20.   30.   50.  ]\n",
      "15\n",
      "17\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "rf_tenor_tickers = pd.read_excel(inputfile, sheet_name='IR Term TICKERS').set_index('TICKER')\n",
    "rf_tenor_dict = rf_tenor_tickers['YEARS'].to_dict()\n",
    "\n",
    "rf_rates_data = pd.read_excel(inputfile, sheet_name='IR Term Structure')\n",
    "rf_rates_data = rf_rates_data.iloc[6:]\n",
    "rf_rates_data.columns = np.insert(rf_rates_data.columns[1:],0,'Dates')\n",
    "rf_rates_data = rf_rates_data.set_index('Dates')\n",
    "\n",
    "def construct_rf_curve(pricing_date: dt.datetime):\n",
    "    pdate_rf_rates = rf_rates_data.loc[pdate]\n",
    "    rf_tenors = np.array([rf_tenor_dict[i] for i in pdate_rf_rates.index])\n",
    "    rf_zrates = pdate_rf_rates.values/100.\n",
    "    rf_curve = risk_free_curve(rf_tenors, rf_zrates)\n",
    "    return rf_curve\n",
    "\n",
    "rf_curve = construct_rf_curve(pdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03111447529753012"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_curve.r(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------\n",
    "# Function library for Hazard Rate Calibration\n",
    "# -----------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "from risk_free_curve import risk_free_curve\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# This function requires: Tenors (years), CDS par spread (bps),\n",
    "# Discount curve (units), Recovery rate (units)\n",
    "# -----------------------------------------------------\n",
    "\n",
    "def CDS_Calibration(Tenors, CDS_par_spread, Discount_curve, RR):\n",
    "    # Vectors to store values:\n",
    "    dt = np.zeros_like(Tenors)\n",
    "    P_t = np.zeros(len(Tenors) + 1)\n",
    "    Lambda_t = np.zeros(len(Tenors))\n",
    "    P_t[0] = 1\n",
    "\n",
    "    # Discrete dt:\n",
    "    dt[0] = Tenors[0]\n",
    "    dt[1:] = np.diff(Tenors)\n",
    "\n",
    "    # Define L:\n",
    "    L = 1 - RR\n",
    "\n",
    "    # JPMorgan method's Boostrapping of Cumulative survival Prob:\n",
    "    Summ = 0\n",
    "    for t, s in enumerate(CDS_par_spread):\n",
    "        if t == 0:\n",
    "            P_t[t + 1] = L / (s / 10000.0 * dt[t] + L)\n",
    "            Lambda_t[t] = -np.log(P_t[t + 1]) / dt[t]\n",
    "        else:\n",
    "            Numerator = 0.0\n",
    "            for i in range(t):\n",
    "                Numerator += Discount_curve[i] * (L * P_t[i] - (L + dt[i] * s / 10000.0) * P_t[i + 1])\n",
    "\n",
    "            Denominator = Discount_curve[t] * (L + dt[t] * s / 10000.0)\n",
    "            P_t[t + 1] = Numerator / Denominator + P_t[t] * L / (L + s / 10000.0 * dt[t])\n",
    "            Lambda_t[t] = (-np.log(P_t[t + 1]) - np.dot(Lambda_t[:t], dt[:t])) / dt[t]\n",
    "\n",
    "    return Lambda_t\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# class to encapsulate hazard rate term structure\n",
    "# -----------------------------------------------------\n",
    "\n",
    "\n",
    "class credit_curve():\n",
    "\n",
    "    def __init__(self, tenors, spread, recovery_rate, rf_curve: risk_free_curve):\n",
    "        self.rf_curve = rf_curve\n",
    "        self.tenors = tenors\n",
    "        self.spread = spread\n",
    "        self.rr = recovery_rate\n",
    "        self._calibrate()\n",
    "\n",
    "    def _calibrate(self):\n",
    "        discount_curve = [self.rf_curve.Z(t) for t in self.tenors]\n",
    "        self.piecewise_hr = CDS_Calibration(self.tenors, self.spread, discount_curve, self.rr)\n",
    "\n",
    "    def hazard_rate(self, t):\n",
    "        for i in range(len(self.tenors)):\n",
    "            if (t <= self.tenors[i]):\n",
    "                return self.piecewise_hr[i]\n",
    "        return self.piecewise_hr[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# Functions for processing Bloomberg Data\n",
    "# ----------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ConvertibleBondClass import ConvertibleBond\n",
    "from AndersonBuffumPricer import AndersenBuffumPricer\n",
    "\n",
    "\n",
    "# process call put schedule data\n",
    "def process_call_put_schedule_data(schedule_data):\n",
    "    ISINs = schedule_data.columns[1::4]\n",
    "    schedules = {}\n",
    "    for ISIN in ISINs:\n",
    "        loc = schedule_data.columns.get_loc(ISIN)\n",
    "        call = schedule_data.iloc[:,loc:loc+2][1:].dropna()\n",
    "        call.columns = ['date','price']\n",
    "        call['date'] = pd.to_datetime(call['date'])\n",
    "        put = schedule_data.iloc[:,loc+2:loc+4][1:].dropna()\n",
    "        put.columns = ['date','price']\n",
    "        put['date'] = pd.to_datetime(put['date'])\n",
    "        schedules[ISIN] = (call,put)\n",
    "    return schedules\n",
    "\n",
    "\n",
    "# parse bloomberg cds spread data\n",
    "def parse_BBG_cds_spread(ISIN, cds_data):\n",
    "    try:\n",
    "        r = cds_data.index[cds_data['ISIN'] == ISIN].tolist()[0] + 1\n",
    "        data = cds_data.iloc[r]\n",
    "        sprd = data.values[2:]\n",
    "        if(any(np.isnan(s) for s in sprd)):\n",
    "            return np.array([])\n",
    "        else:\n",
    "            return sprd\n",
    "    except:\n",
    "        return np.array([])\n",
    "\n",
    "\n",
    "def ABpricer_on_BBG_data(row, pdate, cds_data, cp_schedules, rf_curve, p, use_cds_term_structure=False):\n",
    "    \n",
    "    contract_info = {\n",
    "        'maturity_date': row['MATURITY'],\n",
    "        'coupon_rate': row['CPN'],\n",
    "        'coupon_freq': row['CPN_FREQ'],\n",
    "        'notional': 1000,\n",
    "        'conv_ratio': None,  # will be derived from conv_price in the code\n",
    "        'conv_price': row['CV_CNVS_PX'],\n",
    "        'callable': row['CALLABLE'] == 'Y',\n",
    "        'puttable': row['PUTABLE'] == 'Y',\n",
    "    }\n",
    "\n",
    "    if (contract_info['callable'] or contract_info['puttable']):\n",
    "        ISIN = row['ISIN']\n",
    "        if (ISIN in cp_schedules):\n",
    "            contract_info['call_schedule'], contract_info['put_schedule'] = cp_schedules[ISIN]\n",
    "        else:\n",
    "            contract_info['call_schedule'], contract_info['put_schedule'] = (None, None)\n",
    "\n",
    "    if 'SOFT CALL 20-30' in row:\n",
    "        contract_info['softcall'] = row['SOFT CALL 20-30'] == 'Y'\n",
    "    else:\n",
    "        contract_info['softcall'] = False\n",
    "\n",
    "    if (contract_info['softcall']):\n",
    "        contract_info['softcall_start'] = pd.to_datetime(row['SOFT CALL START'])\n",
    "        contract_info['softcall_end'] = pd.to_datetime(row['SOFT CALL END'])\n",
    "        contract_info['softcall_barrier'] = row['SOFT CALL BARRIER']\n",
    "        contract_info['softcall_redempt'] = row['SOFT CALL REDEMPTION']\n",
    "\n",
    "    rr = row['BOND_RECOVERY_RATE']\n",
    "    rr = 0.4 if np.isnan(rr) else rr\n",
    "\n",
    "    if (use_cds_term_structure == True):\n",
    "        credit_spread = parse_BBG_cds_spread(row['ISIN'], cds_data)\n",
    "        credit_tenors = [0.5, 1, 2, 3, 4, 5, 7, 10]\n",
    "    else:\n",
    "        credit_spread = [row['FLAT_CREDIT_SPREAD_CV_MODEL']]\n",
    "        credit_tenors = [5]\n",
    "\n",
    "    model_params = {\n",
    "        'recovery_rate': rr,\n",
    "        'equity_spot': row['CV_MODEL_UNDL_PX'],\n",
    "        'equity_dividend_yield': row['EQY_DVD_YLD_IND'] / 100.,\n",
    "        'equity_flat_vol': row['CV_MODEL_STOCK_VOL'],\n",
    "        'eta': row['STOCK_JUMP_ON_DEFAULT_CV_MODEL'],\n",
    "        'credit tenors': credit_tenors,\n",
    "        'credit spread': credit_spread, \n",
    "    }\n",
    "\n",
    "    CB = ConvertibleBond(contract_info, model_params, rf_curve, p=p)\n",
    "    ABpricer = AndersenBuffumPricer(CB, pdate, dt=1. / 48., dy=0.05)\n",
    "\n",
    "    output = (ABpricer.clean_price(), ABpricer.eq_spot_delta(), ABpricer.eq_spot_gamma(), ABpricer.eq_vega())\n",
    "    return output\n",
    "\n",
    "\n",
    "def reformat_output_data(output_data_original, cb_data_input):\n",
    "    output_data = output_data_original.copy()\n",
    "    output_data['Issuer'] = cb_data_input['NAME'].values\n",
    "    output_data['Maturity'] = cb_data_input['MATURITY'].values\n",
    "    output_data['MKT Price'] = cb_data_input['PX_LAST'].values\n",
    "    output_data['BBG Price'] = cb_data_input['Fair Value'].values\n",
    "    output_data['BBG Delta'] = cb_data_input['CV_MODEL_DELTA_V'].values\n",
    "    output_data['BBG Gamma'] = cb_data_input['CV_MODEL_GAMMA_V'].values\n",
    "    output_data['BBG Vega'] = cb_data_input['CV_MODEL_VEGA'].values\n",
    "    output_data['CONV PX'] = cb_data_input['CV_CNVS_PX'].values\n",
    "    output_data['EQ Spot'] = cb_data_input['CV_MODEL_UNDL_PX'].values\n",
    "    output_data['EQ Vol'] = cb_data_input['CV_MODEL_STOCK_VOL'].values\n",
    "    output_data['Flat CDS Spread'] = cb_data_input['FLAT_CREDIT_SPREAD_CV_MODEL'].values\n",
    "\n",
    "    cols_order = [\n",
    "        'Issuer', 'Maturity', 'EQ Spot', 'CONV PX', 'EQ Vol', 'Flat CDS Spread',\n",
    "        'MKT Price', 'BBG Price', 'ABM Price', 'BBG Delta', 'ABM Delta',\n",
    "        'BBG Gamma', 'ABM Gamma', 'BBG Vega', 'ABM Vega']\n",
    "\n",
    "    output_data = output_data.loc[:, cols_order]\n",
    "    output_data['Maturity'] = output_data['Maturity'].astype(str)\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "from risk_free_curve import risk_free_curve\n",
    "from cds_function import credit_curve\n",
    "\n",
    "class ConvertibleBond():\n",
    "\n",
    "    def __init__(self, contract_info: dict, model_params: dict, rf_curve: risk_free_curve, p=0.0):\n",
    "\n",
    "        self.p = p  #control elasticity between eq spot and default intensity\n",
    "\n",
    "        self.m_date = contract_info['maturity_date']\n",
    "        self.c_rate = contract_info['coupon_rate'] / 100.\n",
    "        self.c_freq = contract_info['coupon_freq']\n",
    "        self.notional = contract_info['notional']\n",
    "\n",
    "        if (('conv_ratio' in contract_info.keys()) and (contract_info['conv_ratio'] != None)):\n",
    "            self.cv_ratio = contract_info['conv_ratio']\n",
    "        else:\n",
    "            self.cv_ratio = self.notional / contract_info['conv_price']\n",
    "\n",
    "        self.callable = contract_info['callable']\n",
    "        self.puttable = contract_info['puttable']\n",
    "        if (self.callable):\n",
    "            self.call_schedule = contract_info['call_schedule']\n",
    "        if (self.puttable):\n",
    "            self.put_schedule = contract_info['put_schedule']\n",
    "\n",
    "        self.softcall = contract_info['softcall']\n",
    "        if (self.softcall):\n",
    "            self.softcallinfo = {\n",
    "                'start': contract_info['softcall_start'],\n",
    "                'end': contract_info['softcall_end'],\n",
    "                'barrier': contract_info['softcall_barrier'],\n",
    "                'redemption': contract_info['softcall_redempt'] * (self.notional / 100.),  # data was per 100 notional\n",
    "            }\n",
    "\n",
    "        # risk free rate term structure\n",
    "        self.rf_curve = rf_curve\n",
    "\n",
    "        # hazard rate term structure\n",
    "        self.rr = model_params['recovery_rate']\n",
    "        self.ctenors = model_params['credit tenors']\n",
    "        self.cspread = model_params['credit spread']\n",
    "        self.cd_curve = credit_curve(self.ctenors, self.cspread, self.rr, self.rf_curve)\n",
    "\n",
    "        self.eq_spot = model_params['equity_spot']\n",
    "        self.eq_divd = model_params['equity_dividend_yield']\n",
    "        self.eq_vol = model_params['equity_flat_vol'] / 100.\n",
    "        self.eta = model_params['eta']\n",
    "\n",
    "        # pseudo private variables\n",
    "        self._y0 = np.log(self.eq_spot)\n",
    "\n",
    "    def reset_p(self, newp):\n",
    "        self.p = newp\n",
    "\n",
    "    def reset_eq_spot(self, new_eq_spot):\n",
    "        self.eq_spot = new_eq_spot\n",
    "        self._y0 = np.log(self.eq_spot)\n",
    "\n",
    "    def r(self, t):\n",
    "        return self.rf_curve.r(t)\n",
    "\n",
    "    def Z(self, t):\n",
    "        return self.rf_curve.Z(t)\n",
    "\n",
    "    def q(self, t):\n",
    "        return self.eq_divd\n",
    "\n",
    "    def lambd(self, t, S):\n",
    "        y = np.log(S)\n",
    "        e = self.p * (self._y0 - y)\n",
    "        h = self.cd_curve.hazard_rate(t)\n",
    "        return h * np.exp(e)\n",
    "\n",
    "    def lambd_yspace(self, t, y):\n",
    "        e = self.p * (self._y0 - y)\n",
    "        h = self.cd_curve.hazard_rate(t)\n",
    "        return h * np.exp(e)\n",
    "\n",
    "    def sigma(self, t):\n",
    "        return self.eq_vol\n",
    "\n",
    "    def simulate_eq_spot_paths(self, M, paths, dt):\n",
    "        np.random.seed(1234567)\n",
    "        y = np.array([[self._y0] * paths])\n",
    "\n",
    "        def simulate_next_y(curr_y, t, dt, paths=paths):\n",
    "            z = np.random.normal(size=paths)\n",
    "            u = np.random.rand(paths)\n",
    "            lambd = self.lambd_yspace(t, curr_y)\n",
    "            drift = (self.r(t) - self.q(t) - (0.5 * self.sigma(t) ** 2) + self.eta * lambd) * dt\n",
    "            randw = self.sigma(t) * np.sqrt(dt) * z\n",
    "            jumpN = u <= lambd * dt\n",
    "            return curr_y + drift + randw - self.eta * jumpN\n",
    "\n",
    "        for m in range(0, M):\n",
    "            nexty = simulate_next_y(y[-1], m * dt, dt)\n",
    "            y = np.vstack((y, nexty))\n",
    "\n",
    "        return np.exp(y).T  # return paths x T-step matrix\n",
    "\n",
    "    def soft_call_prob(self, pricing_date, M=20, N=30, paths=1000):\n",
    "        T2 = (self.softcallinfo['end'] - pricing_date).days / 365.25\n",
    "        T1 = (self.softcallinfo['start'] - pricing_date).days / 365.25\n",
    "\n",
    "        dt = 1. / 260  # apply 20-30 soft call logic in business days\n",
    "        D1 = int(T1 / dt)\n",
    "        D2 = int(T2 / dt)\n",
    "\n",
    "        paths = self.simulate_eq_spot_paths(D2, paths, dt)\n",
    "        self.soft_call_paths = paths[:, D1 - 1:D2 - 1]\n",
    "\n",
    "        def soft_call_triggered(path, M, N, barrier):\n",
    "            for i in range(N, len(path)):\n",
    "                roll_window = path[i - N:i]\n",
    "                hits = len(roll_window[roll_window >= barrier])\n",
    "                if (hits >= M):\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "        b = self.softcallinfo['barrier']\n",
    "        triggered = np.array([soft_call_triggered(path, M, N, b) for path in self.soft_call_paths])\n",
    "        soft_call_prob = len(triggered[triggered]) / len(self.soft_call_paths)\n",
    "        return soft_call_prob\n",
    "\n",
    "    def soft_call_approx_1of1_barrier(self, pricing_date):\n",
    "        soft_call_prob = self.soft_call_prob(pricing_date)\n",
    "        soft_call_paths = self.soft_call_paths\n",
    "        max_per_path = soft_call_paths.max(axis=1)\n",
    "        barrier_rank = int(soft_call_prob * len(soft_call_paths))\n",
    "        barrier_argu = max_per_path.argsort()[-barrier_rank]\n",
    "        barrier_1of1 = max_per_path[barrier_argu]\n",
    "        return barrier_1of1\n",
    "\n",
    "    def fixed_coupon_bond_price(self, pricing_date: dt.datetime):\n",
    "        pdate_ttm = (self.m_date - pricing_date).days / 365.25\n",
    "        coupon_dt = 1.0 / float(self.c_freq)\n",
    "        coupon_ttm = np.arange(0, pdate_ttm + 1e-4, coupon_dt)\n",
    "        coupon = self.c_rate * coupon_dt * self.notional\n",
    "        pv_notional = self.notional * self.rf_curve.Z(pdate_ttm)\n",
    "        pv_coupons = [self.rf_curve.Z(pdate_ttm - tau) * coupon for tau in coupon_ttm]\n",
    "        return np.sum(pv_coupons) + pv_notional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88391701, 0.12693819, 0.34749253, 0.94901707])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# Crank-Nicolson Finite Difference Solver for\n",
    "# Andersen-Buffum Convertible Bond model\n",
    "# ------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from ConvertibleBondClass import ConvertibleBond\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# an efficient tridiagonal-matrix solver\n",
    "# -----------------------------------------------------\n",
    "\n",
    "def TDMA(a, b, c, d):\n",
    "    # tridiagonal-matrix solver: a = Lower Diag, b = Main Diag, c = Upper Diag, d = solution vector\n",
    "    n = len(d)\n",
    "    w = np.zeros(n - 1, float)\n",
    "    g = np.zeros(n, float)\n",
    "    p = np.zeros(n, float)\n",
    "\n",
    "    w[0] = c[0] / b[0]\n",
    "    g[0] = d[0] / b[0]\n",
    "\n",
    "    for i in range(1, n - 1):\n",
    "        w[i] = c[i] / (b[i] - a[i - 1] * w[i - 1])\n",
    "    for i in range(1, n):\n",
    "        g[i] = (d[i] - a[i - 1] * g[i - 1]) / (b[i] - a[i - 1] * w[i - 1])\n",
    "    p[n - 1] = g[n - 1]\n",
    "    for i in range(n - 1, 0, -1):\n",
    "        p[i - 1] = g[i - 1] - w[i - 1] * p[i]\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Crank-Nicolson Finite Difference Solver for\n",
    "# Andersen-Buffum Convertible Bond model\n",
    "# ------------------------------------------------------\n",
    "\n",
    "class AndersenBuffumPricer():\n",
    "    \n",
    "    theta = 0.5  # keep it as 0.5 to use Crank-Nicolson Method\n",
    "    y_grid_coverage = 4  # no of stddev covered by the y-grid\n",
    "\n",
    "    def __init__(self, sec: ConvertibleBond, pdate: dt.datetime, dt=1 / 48, dy=0.05):\n",
    "        \n",
    "        self.dt = dt\n",
    "        self.dy = dy\n",
    "        self.sec = sec\n",
    "        self.pdate = pdate\n",
    "\n",
    "        # discretize time to maturity\n",
    "        self.ttm = (sec.m_date - pdate).days / 365.25\n",
    "        self.M = int(self.ttm / dt)  # round down to nearest integer\n",
    "        self.T = self.M * dt\n",
    "        self.rf_T = self.ttm - self.T\n",
    "\n",
    "        # discretize spatial mesh in log-price space\n",
    "        self.y0 = np.log(sec.eq_spot)\n",
    "        y_half_range = self.y_grid_coverage * sec.sigma(self.T) * np.sqrt(self.T)\n",
    "        N_half = int(y_half_range / dy)\n",
    "        self.N = int(2 * N_half)\n",
    "\n",
    "        self.t_knots = np.arange(0, self.M + 1, 1) * self.dt\n",
    "        self.y_knots = self.y0 + np.arange(-N_half, N_half + 0.5, 1) * self.dy\n",
    "        self.S_knots = np.exp(self.y_knots)\n",
    "        self.v_knots = np.array([])\n",
    "        self.S0_index = N_half\n",
    "\n",
    "        self._init_lambd()\n",
    "        self._init_sigma_sq()\n",
    "        self._init_K()\n",
    "        self._init_L()\n",
    "        self._init_R()  # recovery value of the bond upon default\n",
    "\n",
    "        self._init_u()\n",
    "        self._init_d()\n",
    "        self._init_l()\n",
    "\n",
    "        if (self.sec.callable):\n",
    "            self.callable_grid = self._setup_callable_grid()\n",
    "\n",
    "        if (self.sec.puttable):\n",
    "            self.puttable_grid = self._setup_puttable_grid()\n",
    "\n",
    "        if (self.sec.softcall):\n",
    "            self.softcall_barrier = self.sec.soft_call_approx_1of1_barrier(pdate)\n",
    "            self.softcall_barrier_index = np.argmax(self.S_knots >= self.softcall_barrier)\n",
    "            self.softcall_end_tau = (self.sec.m_date - self.sec.softcallinfo['end']).days / 365.25\n",
    "            self.softcall_start_tau = (self.sec.m_date - self.sec.softcallinfo['start']).days / 365.25\n",
    "\n",
    "    def _setup_strike_grid(self, schedule):\n",
    "        if schedule is None:\n",
    "            return np.ones(self.M + 1) * self.sec.notional\n",
    "\n",
    "        dates = schedule['date'].values\n",
    "        prices = schedule['price'].values * (self.sec.notional / 100.)  # data was per 100 notional\n",
    "        call_taus = [(self.sec.m_date - d).days / 365.25 for d in dates]\n",
    "        call_grid = np.zeros(self.M + 1)\n",
    "        for m in range(0, self.M + 1):\n",
    "            for call_t, call_price in zip(call_taus, prices):\n",
    "                if (self.t_knots[m] < call_t and call_t <= self.t_knots[m + 1]):\n",
    "                    call_grid[m + 1] = call_price\n",
    "\n",
    "        return call_grid\n",
    "\n",
    "    def _setup_callable_grid(self):\n",
    "        return self._setup_strike_grid(self.sec.call_schedule)\n",
    "\n",
    "    def _setup_puttable_grid(self):\n",
    "        return self._setup_strike_grid(self.sec.put_schedule)\n",
    "\n",
    "    def reset_p(self, newp):\n",
    "        self.sec.reset_p(newp)\n",
    "        self.__init__(self.sec, self.pdate, self.dt, self.dy)\n",
    "\n",
    "    def refresh_security(self, sec: ConvertibleBond):\n",
    "        self.sec = sec\n",
    "        self.__init__(self.sec, self.pdate, self.dt, self.dy)\n",
    "\n",
    "    def coupon_stream(self):\n",
    "        cp_dt = 1.0 / float(self.sec.c_freq)\n",
    "        cp = self.sec.c_rate * cp_dt * self.sec.notional\n",
    "        cp_stream = np.zeros(self.M + 1)\n",
    "        # enumerate in backward time (to be compatible with solver)\n",
    "        step = int(round(cp_dt / self.dt, 0))\n",
    "        for m in np.arange(0, self.M + 1, step):\n",
    "            cp_stream[m] = cp\n",
    "        return cp_stream\n",
    "\n",
    "    def accrued_interests(self):\n",
    "        coupons = self.coupon_stream()\n",
    "        accrued = np.zeros(self.M + 1)\n",
    "        c_index = np.argwhere(coupons > 0).flatten()\n",
    "        c_start = c_index\n",
    "        c_end = np.append(c_index[1:] - 1, len(coupons) - 2)\n",
    "        for start, end in zip(c_start, c_end):\n",
    "            c = coupons[start]\n",
    "            slots = end - start + 1.\n",
    "            accrued[start:end + 1] = (c / slots) * np.arange(slots, 0, -1)\n",
    "        accrued = accrued - coupons\n",
    "        return accrued\n",
    "\n",
    "    def initial_condition(self):\n",
    "        eq = self.sec.cv_ratio * self.S_knots\n",
    "        bond = self.sec.notional\n",
    "        return np.maximum(eq, bond) + self.coupon_stream()[0]\n",
    "\n",
    "    def bc_lower(self):\n",
    "        recovery = np.array([self.sec.rr * self.sec.notional] * (self.M + 1))\n",
    "        return recovery + self.accrued_interests()\n",
    "\n",
    "    def bc_upper(self):\n",
    "        eq = np.array([self.sec.cv_ratio * self.S_knots[-1]] * (self.M + 1))\n",
    "        return eq + self.accrued_interests()\n",
    "\n",
    "    def _init_lambd(self):\n",
    "        lambd = np.zeros((self.M + 1, self.N + 1))\n",
    "        for m, tau in np.ndenumerate(self.t_knots):\n",
    "            t = self.ttm - tau  # tau is backward time here\n",
    "            lambd[m] = self.sec.lambd(t, self.S_knots)\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def _init_sigma_sq(self):\n",
    "        self.sigma_sq = np.array([self.sec.sigma(self.ttm - tau) ** 2 for tau in self.t_knots])\n",
    "\n",
    "    def _init_K(self):\n",
    "        rt = np.array([self.sec.r(self.ttm - tau) for tau in self.t_knots])\n",
    "        qt = np.array([self.sec.q(self.ttm - tau) for tau in self.t_knots])\n",
    "        self.K = self.sec.eta * self.lambd + rt[:, np.newaxis] - qt[:, np.newaxis] - 0.5 * self.sigma_sq[:,\n",
    "                       np.newaxis]  # -----------Warning----------------------\n",
    "\n",
    "    def _init_L(self):\n",
    "        rt = np.array([self.sec.r(self.ttm - tau) for tau in self.t_knots])\n",
    "        self.L = -self.lambd - rt[:, np.newaxis]\n",
    "\n",
    "    def _init_R(self):\n",
    "        R = np.ones((self.M + 1, self.N + 1))\n",
    "        Bond_RR = self.sec.rr * self.sec.notional * R\n",
    "        EQ_conv = (1 - self.sec.eta) * self.sec.cv_ratio * self.S_knots\n",
    "        EQ_RR = np.repeat(np.array([EQ_conv]), self.M + 1, axis=0)\n",
    "        self.R = np.maximum(Bond_RR, EQ_RR)\n",
    "\n",
    "    def _init_u(self):\n",
    "        u = self.K + self.sigma_sq[:, np.newaxis] / self.dy\n",
    "        self.u = (0.5 * self.dt / self.dy) * u\n",
    "\n",
    "    def _init_d(self):\n",
    "        d = -self.L + (self.sigma_sq[:, np.newaxis] / (self.dy ** 2))\n",
    "        self.d = self.dt * d\n",
    "\n",
    "    def _init_l(self):\n",
    "        l = self.K - self.sigma_sq[:, np.newaxis] / self.dy\n",
    "        self.l = (0.5 * self.dt / self.dy) * l\n",
    "\n",
    "    def solve(self):\n",
    "        M = self.M\n",
    "        N = self.N\n",
    "        theta = self.theta\n",
    "\n",
    "        coupons = self.coupon_stream()\n",
    "        accrued = self.accrued_interests()\n",
    "        eq_conv = self.sec.cv_ratio * self.S_knots\n",
    "\n",
    "        bc_lower = self.bc_lower()\n",
    "        bc_upper = self.bc_upper()\n",
    "        v = self.initial_condition()  # (N+1)-array\n",
    "        v_dt = self.initial_condition()  # (N+1)-array\n",
    "\n",
    "        for m in range(0, M):\n",
    "            z = (1 - theta) * (self.u[m, 1:-1] * v[2:])\n",
    "            z += (1 - (1 - theta) * self.d[m, 1:-1]) * v[1:-1]\n",
    "            z -= (1 - theta) * self.l[m, 1:-1] * v[0:-2]\n",
    "            z += self.dt * theta * (self.lambd[m + 1, 1:-1] * self.R[m + 1, 1:-1])\n",
    "            z += self.dt * (1 - theta) * (self.lambd[m, 1:-1] * self.R[m, 1:-1])\n",
    "\n",
    "            v[0] = bc_lower[m + 1]\n",
    "            # v[N] = bc_upper[m+1]\n",
    "            v[N] = 2 * v[N - 1] - v[N - 2]\n",
    "\n",
    "            b = np.zeros(N - 1)\n",
    "            b[0] = -theta * self.l[m + 1, 1] * v[0]\n",
    "            b[-1] = theta * self.u[m + 1, N - 1] * v[N]\n",
    "\n",
    "            C_l_diag = theta * self.l[m + 1, 2:-1]\n",
    "            C_m_diag = 1 + theta * self.d[m + 1, 1:-1]\n",
    "            C_u_diag = -theta * self.u[m + 1, 1:-2]\n",
    "\n",
    "            # solve tridiagonal-matrix problem\n",
    "            v[1:-1] = TDMA(C_l_diag, C_m_diag, C_u_diag, z + b)\n",
    "\n",
    "            # 20-of-30 soft-call by issuer\n",
    "            if (self.sec.softcall):\n",
    "                tau = (m + 1) * self.dt\n",
    "                if (tau >= self.softcall_end_tau and tau <= self.softcall_start_tau):\n",
    "                    barx = self.softcall_barrier_index\n",
    "                    v[barx:-1] = np.minimum(v[barx:-1], self.sec.softcallinfo['redemption'] + accrued[m + 1])\n",
    "\n",
    "            # callable option by issuer has the least priority (iterating backward here)\n",
    "            if (self.sec.callable and self.callable_grid[m + 1] > 0):\n",
    "                call_price = self.callable_grid[m + 1]\n",
    "                v[1:-1] = np.minimum(v[1:-1], call_price + accrued[m + 1])\n",
    "\n",
    "            # puttable option by borrower (priority over issuer's call)\n",
    "            if (self.sec.puttable and self.puttable_grid[m + 1] > 0):\n",
    "                put_price = self.puttable_grid[m + 1]\n",
    "                v[1:-1] = np.maximum(v[1:-1], put_price + accrued[m + 1])\n",
    "\n",
    "                # borrower has option to convert any time (priority over issuer's call)\n",
    "            v[1:-1] = np.maximum(v[1:-1], eq_conv[1:-1] + accrued[m + 1])\n",
    "\n",
    "            # add discrete coupons - coupons are always paid before any conversion/call/put\n",
    "            v[1:-1] = v[1:-1] + coupons[m + 1]\n",
    "\n",
    "        # discount by the risk-free rate for the residual period smaller than dt\n",
    "        self.v_knots = v * self.sec.Z(self.rf_T)\n",
    "\n",
    "    def price(self):\n",
    "        if (len(self.v_knots) == 0):\n",
    "            self.solve()\n",
    "        return self.v_knots[self.S0_index]\n",
    "\n",
    "    def dirty_price(self):\n",
    "        p = self.price()\n",
    "        return p * (100. / self.sec.notional)\n",
    "\n",
    "    def clean_price(self):\n",
    "        dt = 1. / float(self.sec.c_freq)\n",
    "        cp = self.sec.c_rate * dt * 100  # coupon per 100 notional\n",
    "        remain = int(self.ttm / dt)\n",
    "        accrued_t = dt - (self.ttm - remain * dt)\n",
    "        accrued_c = cp * (accrued_t / dt)\n",
    "        return self.dirty_price() - accrued_c\n",
    "\n",
    "    def eq_spot_delta(self):\n",
    "        self.solve()\n",
    "        dvdy = (self.v_knots[self.S0_index + 1] - self.v_knots[self.S0_index - 1]) / (2 * self.dy)\n",
    "        dvds = dvdy / self.sec.eq_spot\n",
    "        delta = dvds / self.sec.cv_ratio  # same convention as  Bloomberg and BlackRock\n",
    "        return delta\n",
    "\n",
    "    def eq_spot_gamma(self):\n",
    "        base_spot = self.sec.eq_spot\n",
    "        abs_shock = min(10.0 / self.sec.cv_ratio, 0.01 * base_spot)\n",
    "\n",
    "        self.sec.reset_eq_spot(base_spot + abs_shock)\n",
    "        self.__init__(self.sec, self.pdate, dt=self.dt, dy=self.dy)\n",
    "        up_delta = self.eq_spot_delta()\n",
    "\n",
    "        self.sec.reset_eq_spot(base_spot - abs_shock)\n",
    "        self.__init__(self.sec, self.pdate, dt=self.dt, dy=self.dy)\n",
    "        dn_delta = self.eq_spot_delta()\n",
    "\n",
    "        # revert to the base state\n",
    "        self.sec.reset_eq_spot(base_spot)\n",
    "        self.__init__(self.sec, self.pdate, dt=self.dt, dy=self.dy)\n",
    "        return (up_delta - dn_delta) / (2 * abs_shock / base_spot)\n",
    "\n",
    "    def eq_vega(self, shock=0.01):\n",
    "        base_vol = self.sec.eq_vol\n",
    "\n",
    "        self.sec.eq_vol = base_vol + shock\n",
    "        self.__init__(self.sec, self.pdate, dt=self.dt, dy=self.dy)\n",
    "        shocked_price = self.dirty_price()\n",
    "\n",
    "        self.sec.eq_vol = base_vol\n",
    "        self.__init__(self.sec, self.pdate, dt=self.dt, dy=self.dy)\n",
    "        base_price = self.dirty_price()\n",
    "\n",
    "        vega = (shocked_price - base_price)\n",
    "        return vega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
